# -*- coding: utf-8 -*-
"""Data Mining Group Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kUlCsnHD9LTxZ57Gu_Bed_0EpE-Gj62j
"""

!pip install -q pandas numpy scikit-learn matplotlib transformers torch xgboost shap

!pip install -q -U google-genai

import os
os.environ["GOOGLE_API_KEY"] = "AIzaSyCI1ikWvyTU6N1m4nTpB5kcJA7_2MjveEE"

import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, learning_curve
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

from sklearn.inspection import permutation_importance
from xgboost import XGBClassifier

"""# DATASET GENERATION"""

RANDOM_SEED = 42
rng = np.random.default_rng(RANDOM_SEED)

# -----------------------
# 1) Simulate base dataset
# -----------------------
def clip(a, lo, hi):
    return np.clip(a, lo, hi)

N = 1500  # >= 1000
states = ["Selangor", "KL", "Johor", "Penang", "Perak", "Sabah", "Sarawak", "Pahang", "Kelantan", "Terengganu"]
income_bands = ["B40", "M40", "T20"]
segments = ["new", "regular", "loyal", "premium"]
genders = ["F", "M"]

df = pd.DataFrame({
    "customer_id": [f"C{100000+i}" for i in range(N)],
    "age": clip(rng.normal(30, 9, N).round(), 18, 65).astype(int),
    "gender": rng.choice(genders, N, p=[0.55, 0.45]),
    "state": rng.choice(states, N, p=[0.22, 0.14, 0.12, 0.08, 0.08, 0.07, 0.07, 0.08, 0.07, 0.07]),
    "income_band": rng.choice(income_bands, N, p=[0.48, 0.40, 0.12]),
    "tenure_days": clip(rng.gamma(shape=2.0, scale=120, size=N).round(), 7, 1500).astype(int),
    "segment": rng.choice(segments, N, p=[0.25, 0.45, 0.22, 0.08]),
})

# A multiplier that adjusts how frequently a customer places orders, based on their segment
seg_mult_orders = df["segment"].map({"new": 0.6, "regular": 1.0, "loyal": 1.5, "premium": 1.8}).values

# A multiplier for Average Order Value (AOV) based on customer segment.
seg_mult_aov = df["segment"].map({"new": 0.9, "regular": 1.0, "loyal": 1.1, "premium": 1.3}).values

# Number of orders placed in the last 90 days.
orders_90d = clip(rng.poisson(lam=3.5 * seg_mult_orders), 0, 40).astype(int)

# Number of orders in the last 30 days, derived from recent activity.
orders_30d = clip((orders_90d * rng.uniform(0.15, 0.65, N)).round(), 0, 20).astype(int)

# Average monetary value per order (RM).
avg_order_value = clip(rng.lognormal(mean=3.7, sigma=0.35, size=N) * seg_mult_aov, 15, 600).round(2)

# Total customer spending in the last 90 days. (with random noise)
total_spend_90d = (orders_90d * avg_order_value * rng.uniform(0.8, 1.2, N)).round(2)

# Number of days since the customer’s most recent purchase.
days_since_last_order = rng.integers(0, 120, N)
days_since_last_order = clip(days_since_last_order - (orders_30d * rng.integers(0, 3, N)), 0, 120).astype(int)

# Number of browsing sessions in the last 30 days.
browse_sessions_30d = clip(rng.poisson(lam=10 * seg_mult_orders) + rng.integers(0, 10, N), 0, 120).astype(int)

# Proportion of shopping carts abandoned before checkout.
cart_abandon_rate = clip(rng.beta(a=2.0, b=5.0, size=N) + (days_since_last_order / 300), 0, 0.98).round(3)

# Proportion of orders returned by the customer.
return_rate = clip(rng.beta(a=1.3, b=15, size=N) + rng.normal(0, 0.01, N), 0, 0.60).round(3)

# Number of refunds requested in the last 90 days.
refund_count_90d = clip(rng.poisson(lam=orders_90d * return_rate * 0.7), 0, 20).astype(int)

# Proportion of purchases made using discounts.
discount_ratio = clip(
    rng.beta(a=2.2, b=4.5, size=N) + (df["income_band"].map({"B40": 0.08, "M40": 0.03, "T20": -0.02}).values),
    0, 0.95
).round(3)

# Frequency of coupon usage across purchases.
coupon_used_rate = clip(rng.beta(a=2.0, b=3.0, size=N) + (discount_ratio - 0.3), 0, 1.0).round(3)

# Proportion of orders delivered later than expected.
delivery_delay_rate = clip(rng.beta(a=1.5, b=12.0, size=N) + rng.normal(0, 0.02, N), 0, 0.70).round(3)

# Number of delayed deliveries in the last 90 days.
late_delivery_count = clip(rng.poisson(lam=orders_90d * delivery_delay_rate * 0.6), 0, 15).astype(int)

# Number of completely failed deliveries.
failed_delivery_count = clip(rng.poisson(lam=orders_90d * 0.01), 0, 5).astype(int)

# Number of customer support tickets raised in the last 90 days.
tickets_90d = clip(rng.poisson(lam=0.3 + (late_delivery_count * 0.15) + (refund_count_90d * 0.12)), 0, 12).astype(int)

# Average time (in hours) taken for customer support to respond.
avg_first_response_hours = clip(rng.lognormal(mean=2.0, sigma=0.5, size=N) + tickets_90d * 0.8, 0.5, 72).round(2)

# Proportion of marketing emails opened by the customer.
email_open_rate = clip(rng.beta(a=2.5, b=3.5, size=N) - (days_since_last_order / 250), 0, 1.0).round(3)

# Proportion of mobile push notifications opened.
push_open_rate = clip(rng.beta(a=2.0, b=4.0, size=N) - (days_since_last_order / 300), 0, 1.0).round(3)

# Accumulated loyalty points held by the customer.
loyalty_points_balance = clip((total_spend_90d * rng.uniform(0.3, 1.2, N)).round(), 0, 50000).astype(int)

# Customer’s rating of the mobile app (1–5).
app_rating = clip(rng.normal(4.1, 0.7, N) - (late_delivery_count * 0.08) - (tickets_90d * 0.06), 1, 5).round(1)

df = df.assign(
    orders_90d=orders_90d,
    orders_30d=orders_30d,
    avg_order_value=avg_order_value,
    total_spend_90d=total_spend_90d,
    days_since_last_order=days_since_last_order,
    browse_sessions_30d=browse_sessions_30d,
    cart_abandon_rate=cart_abandon_rate,
    return_rate=return_rate,
    refund_count_90d=refund_count_90d,
    discount_ratio=discount_ratio,
    coupon_used_rate=coupon_used_rate,
    delivery_delay_rate=delivery_delay_rate,
    late_delivery_count=late_delivery_count,
    failed_delivery_count=failed_delivery_count,
    tickets_90d=tickets_90d,
    avg_first_response_hours=avg_first_response_hours,
    email_open_rate=email_open_rate,
    push_open_rate=push_open_rate,
    loyalty_points_balance=loyalty_points_balance,
    app_rating=app_rating
)

# Generating Churn Label

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

risk = (
    0.035 * df["days_since_last_order"]
    + 0.9 * df["delivery_delay_rate"] * 10
    + 0.45 * df["refund_count_90d"]
    + 0.35 * df["tickets_90d"]
    + 0.25 * df["cart_abandon_rate"] * 10
    - 0.30 * df["orders_30d"]
    - 0.18 * df["email_open_rate"] * 10
    - 0.15 * df["push_open_rate"] * 10
    - 0.00002 * df["loyalty_points_balance"]
    - 0.40 * (df["app_rating"] - 3.0)
)

p = sigmoid((risk - np.percentile(risk, 55)) / 2.2)
df["churn"] = (rng.uniform(0, 1, N) < p).astype(int)

print("Rows:", len(df))
print("Churn rate:", round(df["churn"].mean(), 3))

# Realistic attempt (injecting missing values)

for col, miss_rate in {
    "income_band": 0.03,
    "avg_first_response_hours": 0.04,
    "app_rating": 0.02,
    "discount_ratio": 0.03,
}.items():
    m = rng.uniform(0, 1, N) < miss_rate
    df.loc[m, col] = np.nan

#LLM used for feedbacks

import json, time, re, os
from google import genai

client = genai.Client()  # uses GOOGLE_API_KEY from environment

INPUT_PATH = "llm_text_generation_input.jsonl"
OUTPUT_PATH = "llm_text_generation_output.jsonl"

# LLM generate feedback text
TEXT_PROMPT = """
You are generating realistic Malaysian e-commerce customer text.
Given the customer profile and behaviour summary, output a JSON object with keys:
- customer_feedback: 1-2 sentences (casual English with occasional Malay, realistic typos ok)
- support_chat_excerpt: 1-2 lines like a chat message (customer side)
- reason_for_low_activity: short phrase
If delivery delay high -> complain about shipping.
If refund high -> complain about product quality/refund.
If churn=0 -> more positive/neutral.
Return ONLY valid JSON with the 3 keys above, no extra commentary.
""".strip()

def build_text_input_row(r):
    return {
        "customer_id": r["customer_id"],
        "segment": r["segment"],
        "income_band": r["income_band"] if pd.notna(r["income_band"]) else "unknown",
        "orders_30d": int(r["orders_30d"]),
        "days_since_last_order": int(r["days_since_last_order"]),
        "late_delivery_count": int(r["late_delivery_count"]),
        "refund_count_90d": int(r["refund_count_90d"]),
        "discount_ratio": float(r["discount_ratio"]) if pd.notna(r["discount_ratio"]) else None,
        "app_rating": float(r["app_rating"]) if pd.notna(r["app_rating"]) else None,
        "churn": int(r["churn"]),
    }

#just to clear any errors of previous attempts
if os.path.exists(OUTPUT_PATH):
    os.remove(OUTPUT_PATH)

# 1) Write INPUT JSONL (prompts)

N_TEXT_ROWS = 500

with open(INPUT_PATH, "w", encoding="utf-8") as f:
    for _, r in df.sample(N_TEXT_ROWS, random_state=RANDOM_SEED).iterrows():
        f.write(json.dumps({"prompt": TEXT_PROMPT, "input": build_text_input_row(r)}, ensure_ascii=False) + "\n")

print("Wrote:", INPUT_PATH, "| rows:", N_TEXT_ROWS)

def extract_json_anywhere(text: str) -> dict:
    """
    Gemini/Gemma sometimes wraps JSON in fences or adds extra text.
    This extracts the first {...} JSON object and parses it.
    """
    if text is None:
        raise ValueError("Empty response text")

    t = text.strip()

    # remove ```json fences if present
    t = re.sub(r"^```json\s*", "", t, flags=re.IGNORECASE)
    t = re.sub(r"^```\s*", "", t)
    t = re.sub(r"\s*```$", "", t)

    # try direct JSON parse first
    try:
        return json.loads(t)
    except Exception:
        pass

    # otherwise find the first JSON object inside the text
    m = re.search(r"\{.*\}", t, flags=re.DOTALL)
    if not m:
        raise ValueError("No JSON object found in response text")
    return json.loads(m.group(0))

def run_llm_text_generation(
    input_path=INPUT_PATH,
    output_path=OUTPUT_PATH,
    model="models/gemma-3-4b-it",
    base_sleep_s=2.2,          # ✅ ~27 req/min (stays under 30/min)
    max_retries_per_row=5
):
    fails = 0
    printed_first_error = False

    with open(input_path, "r", encoding="utf-8") as f_in, open(output_path, "w", encoding="utf-8") as f_out:
        for i, line in enumerate(f_in, start=1):
            obj = json.loads(line)
            prompt = obj["prompt"]
            inp = obj["input"]

            full_text = (
                prompt
                + "\n\nCustomer summary (JSON):\n"
                + json.dumps(inp, ensure_ascii=False)
            )

            attempt = 0
            while True:
                try:
                    resp = client.models.generate_content(model=model, contents=full_text)
                    parsed = extract_json_anywhere(resp.text)

                    out = {
                        "customer_id": inp["customer_id"],
                        "customer_feedback": parsed.get("customer_feedback", ""),
                        "support_chat_excerpt": parsed.get("support_chat_excerpt", ""),
                        "reason_for_low_activity": parsed.get("reason_for_low_activity", "")
                    }

                    f_out.write(json.dumps(out, ensure_ascii=False) + "\n")
                    break  # ✅ success -> next row

                except Exception as e:
                    msg = str(e)

                    # --- Handle 429 rate limit / quota exceeded ---
                    if "429" in msg or "RESOURCE_EXHAUSTED" in msg:
                        attempt += 1
                        if attempt > max_retries_per_row:
                            fails += 1
                            if not printed_first_error:
                                print("FIRST ERROR:", repr(e))
                                printed_first_error = True

                            out = {
                                "customer_id": inp["customer_id"],
                                "customer_feedback": "",
                                "support_chat_excerpt": "",
                                "reason_for_low_activity": ""
                            }
                            f_out.write(json.dumps(out, ensure_ascii=False) + "\n")
                            break

                        # Respect retry delay if present in error
                        wait_s = 30.0
                        m = re.search(r"retry in ([0-9.]+)s", msg)
                        if m:
                            wait_s = max(5.0, float(m.group(1)) + 2.0)
                        m2 = re.search(r"retryDelay.*?([0-9]+)s", msg)
                        if m2:
                            wait_s = max(wait_s, float(int(m2.group(1)) + 2))

                        print(f"[{i}/{N_TEXT_ROWS}] 429 rate limit. Sleeping {wait_s:.1f}s then retrying (attempt {attempt}/{max_retries_per_row})...")
                        time.sleep(wait_s)
                        continue

                    # --- Other errors: fallback ---
                    fails += 1
                    if not printed_first_error:
                        print("FIRST ERROR:", repr(e))
                        printed_first_error = True

                    out = {
                        "customer_id": inp["customer_id"],
                        "customer_feedback": "",
                        "support_chat_excerpt": "",
                        "reason_for_low_activity": ""
                    }
                    f_out.write(json.dumps(out, ensure_ascii=False) + "\n")
                    break

            # Base pacing (prevents hitting 30/min)
            time.sleep(base_sleep_s)

    print("Wrote:", output_path, "| fails:", fails)

# 2) Run LLM -> creates OUTPUT JSONL (now quota-safe)
run_llm_text_generation(model="models/gemma-3-4b-it", base_sleep_s=2.2)

# 3) Merge back into df so df shows text columns
df = merge_llm_text_outputs(df, OUTPUT_PATH)

# 4) Ensure no NaN
for c in ["customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]:
    df[c] = df[c].fillna("")

# quick check
df[["customer_id", "customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]].head(5)

import json
import pandas as pd

# Load LLM output
rows = []
with open("llm_text_generation_output.jsonl", "r", encoding="utf-8") as f:
    for line in f:
        rows.append(json.loads(line))

df_text = pd.DataFrame(rows)

# Merge into main df
df = df.merge(df_text, on="customer_id", how="left")

# Safety: ensure columns always exist
for c in ["customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]:
    if c not in df.columns:
        df[c] = ""
    df[c] = df[c].fillna("")

print("Rows with feedback:", (df["customer_feedback"].str.strip() != "").sum())
df[["customer_id","customer_feedback","support_chat_excerpt","reason_for_low_activity"]].head(5)

with open("llm_text_generation_output.jsonl", "r", encoding="utf-8") as f:
    for _ in range(5):
        print(f.readline())

(df["customer_feedback"].str.strip() != "").sum(), len(df)

df.loc[df["customer_feedback"].str.strip() != "",
       ["customer_id","customer_feedback","support_chat_excerpt","reason_for_low_activity"]].head(10)

# Load output jsonl into df_text and check overlap
import pandas as pd, json

rows = []
with open("llm_text_generation_output.jsonl", "r", encoding="utf-8") as f:
    for line in f:
        rows.append(json.loads(line))

df_text = pd.DataFrame(rows)
print("Output rows:", len(df_text))
print("Unique output customer_id:", df_text["customer_id"].nunique())
print("Overlap with df:", df["customer_id"].isin(df_text["customer_id"]).sum())

df.to_csv("ecommerce_churn_llm_final.csv", index=False)
print("Final dataset saved.")

"""# DATA CHECK


"""

#Import seperately to prevent calling LLM again (40 minutes)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import (
    train_test_split,
    StratifiedKFold,
    GridSearchCV,
    learning_curve
)
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.metrics import (
    accuracy_score,
    f1_score,
    roc_auc_score,
    confusion_matrix
)

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance

from xgboost import XGBClassifier

from transformers import pipeline as hf_pipeline


RANDOM_SEED = 42

df = pd.read_csv("ecommerce_churn_llm_final.csv")
df.head()

def keep_base_column(df, base_col):
    cols = [c for c in df.columns if c == base_col or c.startswith(base_col + "_")]
    if len(cols) <= 1:
        return df  # nothing to do

    # keep the clean base name
    for c in cols:
        if c != base_col:
            df.drop(columns=c, inplace=True)
    return df

for col in ["customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]:
    df = keep_base_column(df, col)

[c for c in df.columns if "feedback" in c or "support_chat" in c or "reason_for" in c]

df.to_csv("ecommerce_churn_llm_slm_dataset.csv", index=False)
print("Final clean dataset saved.")

df[
    df["customer_feedback"].astype(str).str.strip() != ""
][
    ["customer_id", "customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]
].sample(5, random_state=42)

df.groupby("churn")["customer_feedback"].apply(lambda x: x.sample(3, random_state=0))

df[
    ["customer_id", "customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]
].to_csv("feedback_preview.csv", index=False)

"""# DATA CLEANING"""

import pandas as pd
import numpy as np
import re

df = pd.read_csv("ecommerce_churn_llm_slm_dataset.csv")
print("Shape:", df.shape)
df.head()

df.isna().sum()

# standardize column names (remove leading/trailing spaces, replace with _)
df.columns = (
    df.columns
      .str.strip()
      .str.replace(r"\s+", "_", regex=True)
)

# remove duplicate rows
df = df.drop_duplicates()

# If customer_id exists, keep unique customer rows (= one row one cust)
if "customer_id" in df.columns:
    df = df.drop_duplicates(subset=["customer_id"], keep="first")

# identify common column groups (diff dtypes need diff cleaning strategy)
TEXT_COLS = ["customer_feedback", "support_chat_excerpt", "reason_for_low_activity"]
CAT_COLS  = ["gender", "state", "income_band", "segment"]
NUMERIC_COLS = [
    "age","tenure_days","orders_90d","orders_30d","avg_order_value","total_spend_90d",
    "days_since_last_order","browse_sessions_30d","cart_abandon_rate","return_rate",
    "refund_count_90d","discount_ratio","coupon_used_rate","delivery_delay_rate",
    "late_delivery_count","failed_delivery_count","tickets_90d",
    "avg_first_response_hours","email_open_rate","push_open_rate",
    "loyalty_points_balance","app_rating"
]

# coerce types safely
# 1) churn must numeric (0/1)
if "churn" in df.columns:
    df["churn"] = pd.to_numeric(df["churn"], errors="coerce")

# 2) numeric cols : convert numbers stored as text --> numeric
for c in NUMERIC_COLS:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce")

# 3) categories
for c in CAT_COLS:
    if c in df.columns:
        df[c] = df[c].astype("string")

# 4) text
for c in TEXT_COLS:
    if c in df.columns:
        df[c] = df[c].astype("string")

# clean text fields (remove extra space, normalize formatting, convert empty strings --> missing)
def clean_text(x):
    if pd.isna(x):
        return pd.NA
    s = str(x).replace("\u00a0", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return pd.NA if s == "" else s

for c in TEXT_COLS:
    if c in df.columns:
        df[c] = df[c].apply(clean_text)

# handle missing values
# 1) fill missing values with empty string (=nlp wont crash)
for c in TEXT_COLS:
    if c in df.columns:
        df[c] = df[c].fillna("")

# 2) categorical : fill missing with "unknown"
for c in CAT_COLS:
    if c in df.columns:
        df[c] = df[c].fillna("unknown").astype("category")

# 3) numeric : median imputation
for c in NUMERIC_COLS:
    if c in df.columns:
        med = df[c].median()
        df[c] = df[c].fillna(med)

# 4) churn : drop rows if missing, enforce 0/1 int
if "churn" in df.columns:
    df = df[df["churn"].notna()].copy()
    # If churn contains weird values, clip to [0,1] then round
    df["churn"] = df["churn"].clip(0, 1).round().astype(int)

# logical consistency + realistic constraints
def clip_col(col, lo=None, hi=None):
    if col in df.columns:
        if lo is not None:
            df[col] = df[col].clip(lower=lo)
        if hi is not None:
            df[col] = df[col].clip(upper=hi)

# Common realism rules (age & rating limits)
clip_col("age", 18, 80)
clip_col("app_rating", 1, 5)

# Rate/proportion columns should be within [0,1] (probabilities)
for rate_col in [
    "cart_abandon_rate","return_rate","discount_ratio","coupon_used_rate",
    "delivery_delay_rate","email_open_rate","push_open_rate"
]:
    clip_col(rate_col, 0, 1)

# Orders logic: orders_30d cannot exceed orders_90d
if "orders_90d" in df.columns and "orders_30d" in df.columns:
    df["orders_30d"] = np.minimum(df["orders_30d"], df["orders_90d"])

# days_since_last_order cannot be negative
clip_col("days_since_last_order", 0, None)

# counts cannot be negative
for count_col in ["refund_count_90d","late_delivery_count","failed_delivery_count","tickets_90d",
                  "orders_90d","orders_30d","browse_sessions_30d","loyalty_points_balance","tenure_days"]:
    clip_col(count_col, 0, None)

# final quick report
print("\n=== CLEANING REPORT ===")
print("Final shape:", df.shape)

missing_top = df.isna().sum().sort_values(ascending=False).head(15)
print("\nTop missing counts (should be near 0 for most):")
print(missing_top)

if "churn" in df.columns:
    print("\nChurn distribution:")
    print(df["churn"].value_counts())

# Preview some feedback content to verify it looks fine
if "customer_feedback" in df.columns:
    non_empty = df[df["customer_feedback"].str.strip() != ""]
    print("\nNon-empty customer_feedback rows:", len(non_empty))
    display(non_empty[["customer_id","customer_feedback"]].head(8) if "customer_id" in df.columns
            else non_empty[["customer_feedback"]].head(8))

df.to_csv("ecommerce_churn_cleaned.csv")

"""#  EDA"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# post cleaning sanity check
print("Shape:", df.shape)
display(df.head())
display(df.describe(include="all").T)

# churn distribution
plt.figure()
df["churn"].value_counts().plot(kind="bar")
plt.title("Churn Distribution")
plt.xlabel("Churn (0 = No, 1 = Yes)")
plt.ylabel("Number of Customers")
plt.show()

print(df["churn"].value_counts(normalize=True))

# demographic analysis vs churn
# 1) age vs churn
plt.figure()
df.boxplot(column="age", by="churn")
plt.title("Age Distribution by Churn")
plt.suptitle("")
plt.xlabel("Churn")
plt.ylabel("Age")
plt.show()

# 2) gender vs churn
if "gender" in df.columns:
    pd.crosstab(df["gender"], df["churn"], normalize="index").plot(kind="bar")
    plt.title("Churn Rate by Gender")
    plt.ylabel("Proportion")
    plt.show()

# behavioural features vs churn
# 1) orders & activity
behaviour_cols = ["orders_90d","orders_30d","browse_sessions_30d","days_since_last_order"]

for col in behaviour_cols:
    if col in df.columns:
        plt.figure()
        df.boxplot(column=col, by="churn")
        plt.title(f"{col} by Churn")
        plt.suptitle("")
        plt.xlabel("Churn")
        plt.ylabel(col)
        plt.show()

# monetary features vs churn
monetary_cols = ["avg_order_value","total_spend_90d","loyalty_points_balance"]

for col in monetary_cols:
    if col in df.columns:
        plt.figure()
        df.boxplot(column=col, by="churn")
        plt.title(f"{col} by Churn")
        plt.suptitle("")
        plt.xlabel("Churn")
        plt.ylabel(col)
        plt.show()

# service quality & friction indicators
service_cols = [
    "cart_abandon_rate","return_rate","delivery_delay_rate",
    "late_delivery_count","failed_delivery_count","tickets_90d"
]

for col in service_cols:
    if col in df.columns:
        plt.figure()
        df.boxplot(column=col, by="churn")
        plt.title(f"{col} by Churn")
        plt.suptitle("")
        plt.xlabel("Churn")
        plt.ylabel(col)
        plt.show()

# engagement channels vs churn
engagement_cols = ["email_open_rate","push_open_rate","coupon_used_rate"]

for col in engagement_cols:
    if col in df.columns:
        plt.figure()
        df.boxplot(column=col, by="churn")
        plt.title(f"{col} by Churn")
        plt.suptitle("")
        plt.xlabel("Churn")
        plt.ylabel(col)
        plt.show()

# text data completeness
text_cols = ["customer_feedback","support_chat_excerpt","reason_for_low_activity"]

for col in text_cols:
    if col in df.columns:
        non_empty = (df[col].str.strip() != "").sum()
        print(f"{col}: {non_empty} non-empty rows ({non_empty/len(df):.1%})")

# correlation analysis (numeric only)
numeric_df = df.select_dtypes(include=[np.number])

corr = numeric_df.corr()

plt.figure(figsize=(10,8))
plt.imshow(corr)
plt.colorbar()
plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)
plt.yticks(range(len(corr.columns)), corr.columns)
plt.title("Correlation Heatmap (Numeric Features)")
plt.tight_layout()
plt.show()

"""Overall EDA Summary :

The exploratory data analysis reveals that the dataset is well-balanced in terms of churn classes and exhibits realistic customer behaviour patterns. Demographic variables such as age and gender show limited influence on churn, while behavioural, engagement, and service-quality features display clearer separation between churned and non-churned customers. Variables including days since last order, order frequency, browsing activity, delivery performance, cart abandonment, customer support interactions, and engagement rates demonstrate meaningful relationships with churn. Correlation analysis further indicates low multicollinearity among numeric features, suggesting that the dataset is suitable for baseline modelling using interpretable classifiers such as a decision tree.

# FEATURE ENGINEERING
"""

#imports

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from transformers import pipeline as hf_pipeline

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.inspection import permutation_importance
from sklearn.linear_model import LogisticRegression

RANDOM_SEED = 42

# build combined text field (sentiment model need 1 input text = combine feedback + chat)
df = df.copy()
for c in ["customer_feedback", "support_chat_excerpt"]:
    if c in df.columns:
        df[c] = df[c].fillna("").astype(str)

df["combined_text"] = (df["customer_feedback"] + " " + df["support_chat_excerpt"]).str.strip()

# SLM Sentiment Feature (DistilBERT fine tuned on SST-2 sentiment classification, output = pos & neg)
#load model
slm_sentiment = hf_pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

# sentiment labeling func (empty : neutral, otherwise pass to sentiment model : pos/neg)
def slm_sentiment_label(text):
    if not isinstance(text, str) or text.strip() == "":
        return "neutral"
    out = slm_sentiment(text[:512])[0]  # truncate to 512 tokens worth of chars (simple safety)
    return "positive" if out["label"].upper() == "POSITIVE" else "negative"

# batch inference instead of .apply (faster)
texts = df["combined_text"].tolist()
labels = []
BATCH = 32
for i in range(0, len(texts), BATCH):
    batch = texts[i:i+BATCH]
    # replace empty with placeholder to avoid pipeline complaining
    batch_safe = [t if t.strip() != "" else "[EMPTY]" for t in batch]
    outs = slm_sentiment(batch_safe)
    for t, o in zip(batch, outs):
        if t.strip() == "":
            labels.append("neutral")
        else:
            labels.append("positive" if o["label"].upper() == "POSITIVE" else "negative")

df["slm_sentiment"] = labels

# simple text-derived numeric features (keep info from text w/o put raw text into onehotencoder)
df["has_feedback"] = (df["customer_feedback"].str.strip() != "").astype(int)
df["has_support_chat"] = (df["support_chat_excerpt"].str.strip() != "").astype(int)

df["feedback_len"] = df["customer_feedback"].str.len()
df["support_len"] = df["support_chat_excerpt"].str.len()
df["combined_len"] = df["combined_text"].str.len()

# -------------------------------
# 4) Optional business-sense ratio features (orders/sessions & spend/order ratio)
# Why: ratios can be more informative than raw counts
# -------------------------------
if "orders_90d" in df.columns and "browse_sessions_30d" in df.columns:
    df["orders_per_session_approx"] = df["orders_90d"] / (df["browse_sessions_30d"] + 1e-6)

if "total_spend_90d" in df.columns and "orders_90d" in df.columns:
    df["spend_per_order_approx"] = df["total_spend_90d"] / (df["orders_90d"] + 1e-6)

# define ML Inputs
target = "churn"
drop_cols = ["customer_id"] if "customer_id" in df.columns else []

RAW_TEXT_TO_EXCLUDE = ["customer_feedback", "support_chat_excerpt", "reason_for_low_activity", "combined_text"]
RAW_TEXT_TO_EXCLUDE = [c for c in RAW_TEXT_TO_EXCLUDE if c in df.columns]

X = df.drop(columns=[target] + drop_cols + RAW_TEXT_TO_EXCLUDE)
y = df[target]

# split cols into numeric vs categorical
# numeric : scaling, categorical : onehotencoding
numeric_cols = X.select_dtypes(include=["number"]).columns.tolist()
categorical_cols = [c for c in X.columns if c not in numeric_cols]

# preprocessing pipeline (standardize numeric, one-hot encode categorical)
preprocess = ColumnTransformer(
    transformers=[
        ("num", Pipeline([("scaler", StandardScaler())]), numeric_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols),
    ]
)

# Train/test split + CV
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)

# quick check : show engineered cols
print("Engineered columns added:",
      [c for c in ["slm_sentiment","has_feedback","has_support_chat","feedback_len","support_len","combined_len",
                   "orders_per_session_approx","spend_per_order_approx"] if c in df.columns])

print("\nX shape (after excluding raw text):", X.shape)
print("Numeric cols:", len(numeric_cols), "| Categorical cols:", len(categorical_cols))
display(X.head())

# save features & target separately
X.to_csv("X_features.csv", index=False)
y.to_csv("y_target.csv", index=False)

print("Saved X_features.csv and y_target.csv")

"""# DECISION TREE (baseline)"""

# =======================================================
# BASELINE + TUNED DECISION TREE (with feature importance)
# =======================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    roc_auc_score,
    confusion_matrix,
    classification_report
)

# -----------------------------
# 1) Evaluation function
# -----------------------------
def evaluate(model, X_train, y_train, X_test, y_test, name="Model"):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_proba)
    else:
        auc = None

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"\n=== {name} ===")
    print("Accuracy :", round(acc, 4))
    print("F1-score :", round(f1, 4))
    print("ROC-AUC  :", round(auc, 4) if auc is not None else "N/A")
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    return {"model": name, "accuracy": acc, "f1": f1, "roc_auc": auc}


# -----------------------------
# 2) Feature importance (Decision Tree in pipeline)
# -----------------------------
def get_feature_names_from_preprocess(fitted_preprocess, numeric_cols, categorical_cols):
    # numeric names
    num_features = list(numeric_cols)

    # one-hot encoded category names
    ohe = fitted_preprocess.named_transformers_["cat"]
    cat_features = list(ohe.get_feature_names_out(categorical_cols))

    return num_features + cat_features


def plot_dt_feature_importance(trained_pipe, numeric_cols, categorical_cols, top_n=15, title="DT Feature Importance"):
    prep = trained_pipe.named_steps["prep"]
    clf = trained_pipe.named_steps["clf"]

    if not hasattr(clf, "feature_importances_"):
        print("This model does not provide feature_importances_.")
        return

    feature_names = get_feature_names_from_preprocess(prep, numeric_cols, categorical_cols)
    importances = clf.feature_importances_

    s = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(top_n)

    plt.figure(figsize=(8, 6))
    plt.barh(s.index[::-1], s.values[::-1])
    plt.title(title)
    plt.xlabel("Importance")
    plt.ylabel("Feature")
    plt.grid(True, axis="x")
    plt.show()


# -----------------------------
# 3) Baseline Decision Tree
# -----------------------------
results = []

dt_base = Pipeline([
    ("prep", preprocess),
    ("clf", DecisionTreeClassifier(random_state=RANDOM_SEED, class_weight="balanced"))
])

results.append(evaluate(dt_base, X_train, y_train, X_test, y_test, name="DecisionTree (baseline)"))

# Feature importance for baseline
plot_dt_feature_importance(
    trained_pipe=dt_base,
    numeric_cols=numeric_cols,
    categorical_cols=categorical_cols,
    top_n=15,
    title="DecisionTree (baseline) - Feature Importance"
)

# -----------------------------
# 4) Tuned Decision Tree (GridSearchCV)
# -----------------------------
dt_grid = {
    "clf__max_depth": [2, 3, 5, 8, 12, None],
    "clf__min_samples_split": [2, 10, 30],
    "clf__min_samples_leaf": [1, 5, 15]
}

dt_search = GridSearchCV(
    estimator=dt_base,
    param_grid=dt_grid,
    scoring="f1",
    cv=cv,
    n_jobs=-1
)

dt_search.fit(X_train, y_train)
dt_best = dt_search.best_estimator_
print("\nDT best params:", dt_search.best_params_)

results.append(evaluate(dt_best, X_train, y_train, X_test, y_test, name="DecisionTree (tuned)"))

# Feature importance for tuned DT
plot_dt_feature_importance(
    trained_pipe=dt_best,
    numeric_cols=numeric_cols,
    categorical_cols=categorical_cols,
    top_n=15,
    title="DecisionTree (tuned) - Feature Importance"
)

# -----------------------------
# 5) Results summary table
# -----------------------------
results_df = pd.DataFrame(results)
display(results_df)

"""# Helper Function for Plotting Feature Importance"""

# Generic feature importance (works for more models)

def plot_feature_importance_generic(
    trained_pipe,
    X_train,
    y_train,
    numeric_cols,
    categorical_cols,
    model_name,
    top_n=15,
    n_repeats_perm=5
):
    prep = trained_pipe.named_steps["prep"]
    clf = trained_pipe.named_steps["clf"]

    # 1) Tree-based (DT/RF/XGB)
    if hasattr(clf, "feature_importances_"):
        feature_names = get_feature_names_from_preprocess(prep, numeric_cols, categorical_cols)
        importances = clf.feature_importances_
        s = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(top_n)

        plt.figure(figsize=(8, 6))
        plt.barh(s.index[::-1], s.values[::-1])
        plt.title(f"{model_name} - Feature Importance")
        plt.xlabel("Importance")
        plt.ylabel("Feature")
        plt.grid(True, axis="x")
        plt.show()
        return

    # 2) Logistic Regression coefficients
    if isinstance(clf, LogisticRegression) and hasattr(clf, "coef_"):
        feature_names = get_feature_names_from_preprocess(prep, numeric_cols, categorical_cols)
        importances = np.abs(clf.coef_.ravel())
        s = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(top_n)

        plt.figure(figsize=(8, 6))
        plt.barh(s.index[::-1], s.values[::-1])
        plt.title(f"{model_name} - |Coefficient| Importance")
        plt.xlabel("|Coefficient|")
        plt.ylabel("Feature")
        plt.grid(True, axis="x")
        plt.show()
        return

    # 3) Permutation importance fallback (MLP, etc.)
    perm = permutation_importance(
        trained_pipe,
        X_train,
        y_train,
        n_repeats=n_repeats_perm,
        random_state=RANDOM_SEED,
        scoring="f1",
        n_jobs=-1
    )

    # NOTE: permutation_importance returns importances per original columns (before OHE)
    # Since we are using a Pipeline with preprocess, we keep it simple and show original feature columns.

    s = pd.Series(perm.importances_mean, index=X_train.columns).sort_values(ascending=False).head(top_n)

    plt.figure(figsize=(8, 6))
    plt.barh(s.index[::-1], s.values[::-1])
    plt.title(f"{model_name} - Permutation Importance (F1)")
    plt.xlabel("Mean Importance")
    plt.ylabel("Feature")
    plt.grid(True, axis="x")
    plt.show()
